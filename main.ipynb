{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import numpy as np\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from src.byte_tracker import BYTETracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args, Please refer to the original paper for the specific parameter meaning\n",
    "class BYTETrackerArgs:\n",
    "    track_thresh: float = 0.25   #yolo min Confidence degree\n",
    "    track_buffer: int = 60   #The maximum number of vanishing frames of an object\n",
    "    match_thresh: float = 0.5 #match_thresh\n",
    "    aspect_ratio_thresh: float = 3.0 #Length-width ratio\n",
    "    min_box_area: float = 1.0 #Minimum detection box area\n",
    "    mot20: bool = False  #Validation set, invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_label(image, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n",
    "    thickness = 3  # Thickness of the rectangle border\n",
    "    font_scale = 1.0  # Scale of the font for the label\n",
    "    \n",
    "    # Convert box coordinates to integer tuples for drawing\n",
    "    p1, p2 = (int(box[0]), int(box[1])), (int(box[2]), int(box[3]))\n",
    "    \n",
    "    # Draw the rectangle on the image\n",
    "    cv2.rectangle(image, p1, p2, color, thickness=thickness, lineType=cv2.LINE_AA)\n",
    "    \n",
    "    if label:  # Check if a label is provided\n",
    "        # Get the size of the text for the label\n",
    "        w, h = cv2.getTextSize(label, 0, fontScale=font_scale, thickness=thickness)[0]  \n",
    "        \n",
    "        # Determine whether the label should be placed above or below the rectangle\n",
    "        outside = p1[1] - h >= 3\n",
    "        p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n",
    "        \n",
    "        # Draw a filled rectangle for the label background\n",
    "        cv2.rectangle(image, p1, p2, color, -1, cv2.LINE_AA)\n",
    "        \n",
    "        # Put the label text on the image\n",
    "        cv2.putText(image,\n",
    "                    label, \n",
    "                    (p1[0], p1[1] - 2 if outside else p1[1] + h + 2),\n",
    "                    0,\n",
    "                    font_scale,\n",
    "                    txt_color,\n",
    "                    thickness=thickness,  \n",
    "                    lineType=cv2.LINE_AA)\n",
    "        \n",
    "def iou(box: np.ndarray, boxes: np.ndarray):\n",
    "    # Calculate the intersection area between the predicted box and the ground truth boxes\n",
    "    xy_max = np.minimum(boxes[:, 2:], box[2:])  # Maximum x and y coordinates of the intersection\n",
    "    xy_min = np.maximum(boxes[:, :2], box[:2])  # Minimum x and y coordinates of the intersection\n",
    "    inter = np.clip(xy_max - xy_min, a_min=0, a_max=np.inf)  # Clip to ensure non-negative dimensions\n",
    "    inter = inter[:, 0] * inter[:, 1]  # Calculate intersection area\n",
    "    \n",
    "    # Calculate the area of each box\n",
    "    area_boxes = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])  # Ground truth boxes' area\n",
    "    area_box = (box[2] - box[0]) * (box[3] - box[1])  # Predicted box's area\n",
    "    \n",
    "    # Calculate Intersection over Union (IoU)\n",
    "    return inter / (area_box + area_boxes - inter)  # Return the IoU value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('./model/yolo11n.pt')\n",
    " \n",
    "cap = cv2.VideoCapture(\"./video/1.mp4\")\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "fNUMS = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "videoWriter = cv2.VideoWriter(\"./video/1_t.mp4\", fourcc, fps, size)\n",
    "\n",
    "output_file = open('./video/tracking_results1.txt', 'w')\n",
    "\n",
    "\n",
    "byte_tracker = BYTETracker(BYTETrackerArgs(),frame_rate= fps)\n",
    "frame_count = 0  #Used to record the frame number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    " \n",
    "    if success:      \n",
    "\n",
    "        # Run the model on the current frame with a confidence threshold\n",
    "        results = model(frame, conf=0.5, verbose=False)\n",
    "        \n",
    "        # Get the output boxes data as a NumPy array\n",
    "        outputs = results[0].boxes.data.cpu().numpy()\n",
    "        \n",
    "        if outputs is not None:\n",
    "            # Filter for the person class (class ID 0)\n",
    "            person_mask = outputs[:, 5] == 0\n",
    "            outputs = outputs[person_mask]\n",
    "            \n",
    "            # Set confidence for detected persons\n",
    "            for output in outputs:\n",
    "                output[4] = 0.95\n",
    "            \n",
    "            # Update the tracker with the current frame's outputs\n",
    "            tracks = byte_tracker.update(outputs[:, :5], img_info=frame.shape, img_size=frame.shape)\n",
    "            \n",
    "            for track in tracks:\n",
    "                # Calculate IoU between the tracked box and detected boxes\n",
    "                box_iou = iou(track.tlbr, outputs[:, :4])\n",
    "                maxindex = np.argmax(box_iou)\n",
    "                \n",
    "                # Get the bounding box coordinates and confidence\n",
    "                box = outputs[maxindex]\n",
    "                x1, y1, x2, y2 = map(int, box[:4])\n",
    "                confidence = box[4]\n",
    "                \n",
    "                # Write to the txt file\n",
    "                # Format: Frame number, Track ID, x1, y1, x2, y2, Confidence\n",
    "                output_file.write(f\"{frame_count},{track.track_id},{x1},{y1},{x2},{y2},{confidence:.3f}\\n\")\n",
    "                \n",
    "                # Label the detected person in the frame\n",
    "                if outputs[maxindex, 5] == 0:\n",
    "                    box_label(frame, outputs[maxindex], '#' + str(track.track_id) + ' person', (167, 146, 11))\n",
    "                                        \n",
    "        # Display the frame (commented out for now)\n",
    "        # cv2.imshow(\"ByteTrack\", frame)\n",
    "        videoWriter.write(frame)  # Write the frame to the video file\n",
    "        frame_count += 1  # Increment the frame count\n",
    "     \n",
    "        # Exit the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    " \n",
    "    else:\n",
    "        break\n",
    "    \n",
    "# Release resources\n",
    "cap.release()\n",
    "videoWriter.release()\n",
    "cv2.destroyAllWindows()\n",
    "output_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
